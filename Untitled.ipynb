{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_img = cv2.cvtColor(img,cv2.COLOR_BGR2RGB) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(fix_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG = \"img.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray = cv2.imread(IMG,cv2.IMREAD_GRAYSCALE) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img_gray,cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_gray.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_img =cv2.resize(fix_img,(150,150)) # (w,h)\n",
    "plt.imshow(fix_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_ratio=0.5\n",
    "h_ratio=0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_img = cv2.resize(fix_img,(0,0),fix_img,w_ratio,h_ratio)\n",
    "plt.imshow(fix_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(10,15))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(fix_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img.png\")\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"sample\",img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.rectangle(img,pt1=(384,0),pt2=(510,510),color=(0,255,0),thickness=10)\n",
    "plt.imshow(img)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.circle(img=img,center=(100,100),radius=50,color=(255,0,0),thickness=8)\n",
    "plt.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread(\"img.png\")\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"sample\",img)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bin = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "name = \"/home/rohit/hello/dataset/test/Gill Sans MT/image20.\"+\"jpg\"\n",
    "\n",
    "## (1) read\n",
    "img = cv2.imread(name)\n",
    " \n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "pts = cv2.findNonZero(threshed)\n",
    "ret = cv2.minAreaRect(pts)\n",
    "\n",
    "(cx,cy), (w,h), ang = ret\n",
    "if w>h:\n",
    "    w,h = h,w\n",
    "    ang += 0\n",
    "\n",
    "# (4) Find rotated matrix, do rotation\n",
    "M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "#img = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## (5) find and draw the upper and lower boundary of each lines\n",
    "hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "\n",
    "th = 0\n",
    "H,W = img.shape[:2]\n",
    "uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "\n",
    "rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2RGB)\n",
    "for y in uppers:\n",
    "    cv2.line(rotated, (0,y), (W, y), (255,0,0), 1)\n",
    "\n",
    "for y in lowers:\n",
    "    cv2.line(rotated, (0,y), (W, y), (0,255,0), 1)\n",
    "    \n",
    "image_name = [\"/home/rohit/hello/dataset/test/Gill Sans MT/image\"+ str(i)+\".jpg\" for i in range(len(uppers))]\n",
    "            \n",
    "for i in range(len(uppers)):\n",
    "    cv2.imwrite(image_name[i], img[uppers[i]:lowers[i+1],0:W])\n",
    "    \n",
    "\n",
    "#cv2.imwrite(\"result.png\", rotated)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_addr=\"/home/rohit/hello/dataset/test/Gill Sans MT/\"\n",
    "class_files = os.listdir(c_addr)\n",
    "j=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image00.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image01.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image02.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image03.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image04.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image05.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image06.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image07.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image08.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image09.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image010.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image011.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image012.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image013.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image014.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image015.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image016.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image017.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image018.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image019.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image020.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image021.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image022.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image023.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image024.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image10.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image11.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image12.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image13.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image14.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image15.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image16.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image17.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image18.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image19.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image110.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image111.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image112.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image113.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image114.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image115.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image116.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image117.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image118.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image119.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image120.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image121.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image122.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image123.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image124.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image125.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image126.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image127.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image128.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image129.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image130.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image131.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image132.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image133.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image20.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image21.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image22.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image23.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image24.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image25.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image26.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image27.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image28.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image29.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image210.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image211.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image212.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image213.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image214.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image215.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image216.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image217.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image218.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image219.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image220.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image221.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image222.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image223.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image224.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image225.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image30.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image31.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image32.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image33.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image34.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image35.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image36.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image37.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image38.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image39.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image310.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image311.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image312.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image313.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image314.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image315.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image316.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image317.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image318.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image319.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image320.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image321.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image322.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image323.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image324.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image40.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image41.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image42.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image43.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image44.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image45.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image46.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image47.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image48.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image49.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image410.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image411.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image412.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image413.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image414.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image415.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image416.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image417.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image418.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image419.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image420.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image421.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image422.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image423.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image424.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image425.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image426.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image427.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image428.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image429.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image50.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image51.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image52.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image53.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image54.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image55.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image56.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image57.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image58.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image59.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image510.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image511.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image512.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image513.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image514.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image515.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image516.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image517.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image518.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image519.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image520.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image521.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image522.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image523.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image524.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image525.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image526.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image527.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image528.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image529.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image530.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image60.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image61.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image62.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image63.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image64.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image65.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image66.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image67.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image68.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image69.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image610.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image611.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image612.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image613.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image614.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image615.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image616.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image617.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image618.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image619.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image620.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image621.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image622.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image623.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image624.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image625.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image626.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image627.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image628.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image629.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image630.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image631.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image632.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image633.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image70.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image71.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image72.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image73.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image74.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image75.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image76.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image77.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image78.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image79.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image710.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image711.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image712.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image713.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image714.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image715.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image716.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image717.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image718.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image719.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image720.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image721.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image722.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image723.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image724.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image725.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image726.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image727.jpg']\n",
      "['/home/rohit/hello/dataset/test/Gill Sans MT//image80.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image81.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image82.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image83.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image84.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image85.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image86.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image87.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image88.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image89.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image810.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image811.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image812.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image813.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image814.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image815.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image816.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image817.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image818.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image819.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image820.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image821.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image822.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image823.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image824.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image825.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image826.jpg', '/home/rohit/hello/dataset/test/Gill Sans MT//image827.jpg']\n"
     ]
    }
   ],
   "source": [
    "for sc in class_files:\n",
    "    image_addr = os.path.join(c_addr,sc)\n",
    "    img = cv2.imread(image_addr)\n",
    "\n",
    "\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ## (2) threshold\n",
    "    th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "            \n",
    "            \n",
    "    hist = cv2.reduce(threshed,0, cv2.REDUCE_AVG).reshape(-1)\n",
    "            \n",
    "    th = 0\n",
    "    H,W = img.shape[:2]\n",
    "    left = [x for x in range(W-1) if hist[x]<=th and hist[x+1]>th]\n",
    "    right = [x for x in range(W-1) if hist[x]>th and hist[x+1]<=th]\n",
    "        \n",
    "            \n",
    "\n",
    "    image_name = [c_addr+\"/image\"+  str(j)+  str(i)+\".jpg\" for i in range(len(left))]\n",
    "    j+=1\n",
    "           \n",
    "            \n",
    "            \n",
    "    print(image_name)\n",
    "                \n",
    "    for i in range(min(len(left),len(right))):\n",
    "        cv2.imwrite(image_name[i],img[0:H,left[i]:right[i]])\n",
    "                \n",
    "                \n",
    "\n",
    "    os.remove(image_addr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "H,W = img.shape[:2]\n",
    "print(H)\n",
    "print(W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(rotated)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "uppers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#img = cv2.imread(\"img.png\")\n",
    "\n",
    "while True:\n",
    "    cv2.imshow(\"sample\",rotated)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(uppers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) read\n",
    "import numpy as np\n",
    "import cv2\n",
    "img = cv2.imread(\"sc2.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "pts = cv2.findNonZero(threshed)\n",
    "ret = cv2.minAreaRect(pts)\n",
    "\n",
    "(cx,cy), (w,h), ang = ret\n",
    "if w>h:\n",
    "    w,h = h,w\n",
    "    ang += 0\n",
    "\n",
    "# (4) Find rotated matrix, do rotation\n",
    "M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "#img = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## (5) find and draw the upper and lower boundary of each lines\n",
    "hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "print(hist)\n",
    "\n",
    "th = 0\n",
    "H,W = img.shape[:2]\n",
    "uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "\n",
    "\n",
    "rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "cv2.imwrite(\"screen_result.png\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[uppers[13]:lowers[14],0:W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dis(image,map):\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.imshow(image,cmap=map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis(threshed,\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = cv2.reduce(threshed,0, cv2.REDUCE_AVG).reshape(-1)\n",
    "print(hist)\n",
    "th = 0\n",
    "H,W = img.shape[:2]\n",
    "left = [x for x in range(W-1) if hist[x]<=th and hist[x+1]>th]\n",
    "right = [x for x in range(W-1) if hist[x]>th and hist[x+1]<=th]\n",
    "print(left)\n",
    "print(right)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in left:\n",
    "    cv2.line(img, (x,0), (x,H), (255,0,0), 1)\n",
    "\n",
    "for x in right:\n",
    "    cv2.line(img, (x,0), (x,H), (0,255,0), 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in range(len(left)):\n",
    "    \n",
    "    crop = img[0:H,left[x]:right[x]]\n",
    "    cv2.imwrite(\"img\"+str(x)+\".jpg\",crop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dis(crop,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imwrite(\"test.jpg\",img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## (1) read\n",
    "img = cv2.imread(\"test.jpg\")\n",
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "pts = cv2.findNonZero(threshed)\n",
    "ret = cv2.minAreaRect(pts)\n",
    "\n",
    "(cx,cy), (w,h), ang = ret\n",
    "if w>h:\n",
    "    w,h = h,w\n",
    "    ang += 0\n",
    "\n",
    "# (4) Find rotated matrix, do rotation\n",
    "M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "#img = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## (5) find and draw the upper and lower boundary of each lines\n",
    "hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "\n",
    "th = 0\n",
    "H,W = img.shape[:2]\n",
    "uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "\n",
    "rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2RGB)\n",
    "print((uppers))\n",
    "print((lowers))\n",
    "for y in uppers:\n",
    "    cv2.line(img, (0,y), (W, y), (255,0,0), 1)\n",
    "\n",
    "for y in lowers:\n",
    "    cv2.line(img, (0,y), (W, y), (0,255,0), 1)\n",
    "\n",
    "\n",
    "\n",
    "cv2.imwrite(\"screen_result2.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "image = cv2.imread('sc3.jpg')\n",
    "\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "blur = cv2.GaussianBlur(gray, (7,7), 0)\n",
    "thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]\n",
    "\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (5,5))\n",
    "dilate = cv2.dilate(thresh, kernel, iterations=4)\n",
    "\n",
    "cnts = cv2.findContours(dilate, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = cnts[0] if len(cnts) == 2 else cnts[1]\n",
    "\n",
    "for c in cnts:\n",
    "    x,y,w,h = cv2.boundingRect(c)\n",
    "    cv2.rectangle(dilate, (x, y), (x + w, y + h), (36,255,12), 2)\n",
    "\n",
    "#cv2.imshow('thresh', thresh)\n",
    "#cv2.imshow('dilate', dilate)\n",
    "#cv2.imshow('image', image)\n",
    "#cv2.waitKey()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(dilate,cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel = np.ones((6,6),dtype=np.uint8)\n",
    "\n",
    "\n",
    "result = cv2.erode(dilate,kernel,iterations=3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(result,cmap='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.morphologyEx(result,cv2.MORPH_GRADIENT,kernel)\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(image,cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread('sc2.jpg')\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "pts = cv2.findNonZero(threshed)\n",
    "ret = cv2.minAreaRect(pts)\n",
    "print(ret)\n",
    "(cx,cy), (w,h), ang = ret\n",
    "if w>h:\n",
    "    w,h = h,w\n",
    "    ang += 90\n",
    "\n",
    "# (4) Find rotated matrix, do rotation\n",
    "M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "#img = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## (5) find and draw the upper and lower boundary of each lines\n",
    "hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "\n",
    "th = 0\n",
    "H,W = img.shape[:2]\n",
    "uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "\n",
    "rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2RGB)\n",
    "for y in uppers:\n",
    "    cv2.line(img, (0,y), (W, y), (255,0,0), 1)\n",
    "\n",
    "for y in lowers:\n",
    "    cv2.line(img, (0,y), (W, y), (0,255,0), 1)\n",
    "\n",
    "cv2.imwrite(\"screen_result.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(rotated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY_INV|cv2.THRESH_OTSU)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "pts = cv2.findNonZero(threshed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"cropped.png\", img)\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = img[uppers[2]:lowers[2],0:W]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"cropped.png\", img)\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img  = cv2.rotate(img,cv2.ROTATE_90_CLOCKWISE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cv2.imwrite(\"cropped.png\", img)\n",
    "fig = plt.figure(figsize=(20,20))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "pts = cv2.findNonZero(threshed)\n",
    "ret = cv2.minAreaRect(pts)\n",
    "\n",
    "(cx,cy), (w,h), ang = ret\n",
    "if w>h:\n",
    "    w,h = h,w\n",
    "    ang += 0\n",
    "\n",
    "# (4) Find rotated matrix, do rotation\n",
    "M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "#img = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## (5) find and draw the upper and lower boundary of each lines\n",
    "hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "      \n",
    "\n",
    "th = 0\n",
    "H,W = img.shape[:2]\n",
    "uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "\n",
    "rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2RGB)\n",
    "for y in uppers:\n",
    "    cv2.line(img, (0,y), (W, y), (255,0,0), 1)\n",
    "\n",
    "for y in lowers:\n",
    "    cv2.line(img, (0,y), (W, y), (0,255,0), 1)\n",
    "\n",
    "cv2.imwrite(\"screen_result.png\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ['Times New Roman']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "dir = \"dataset/Arial\"\n",
    "list = os.listdir(dir) # dir is your directory path\n",
    "number_files = len(list)\n",
    "print(list)\n",
    "\n",
    "\n",
    "for path in output:\n",
    "    base_dir='dataset/'\n",
    "    img='img.jpg'\n",
    "    full_path= base_dir+path+\"/\"+img\n",
    "    img = cv2.imread(full_path)\n",
    "    \n",
    "    \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "## (2) threshold\n",
    "    th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "## (3) minAreaRect on the nozeros\n",
    "    pts = cv2.findNonZero(threshed)\n",
    "    ret = cv2.minAreaRect(pts)\n",
    "\n",
    "    (cx,cy), (w,h), ang = ret\n",
    "    if w>h:\n",
    "        w,h = h,w\n",
    "        ang += 0\n",
    "\n",
    "# (4) Find rotated matrix, do rotation\n",
    "    M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "    rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "#img = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "## (5) find and draw the upper and lower boundary of each lines\n",
    "    hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "\n",
    "    th = 0\n",
    "    H,W = img.shape[:2]\n",
    "    uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "    lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "    print(uppers)\n",
    "    print(lowers)\n",
    "\n",
    "    rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2RGB)\n",
    "    for y in uppers:\n",
    "        cv2.line(img, (0,y), (W, y), (255,0,0), 1)\n",
    "\n",
    "    for y in lowers:\n",
    "        cv2.line(img, (0,y), (W, y), (0,255,0), 1)\n",
    "\n",
    "    cv2.imwrite(\"image_result.png\", img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data generator\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "...\n",
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('dataset/train/',target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "# load and iterate validation dataset\n",
    "val_it = datagen.flow_from_directory('dataset/Validation/', target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "# load and iterate test dataset\n",
    "test_it = datagen.flow_from_directory('dataset/test/', target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "#import tensorflow_datasets as tfds\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "URL = \"https://tfhub.dev/google/tf2-preview/mobilenet_v2/feature_vector/2\"\n",
    "feature_extractor = hub.KerasLayer(URL,\n",
    "                                   input_shape=(224,224,3))\n",
    "\n",
    "feature_batch = feature_extractor(32)\n",
    "print(feature_batch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_extractor.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  feature_extractor,\n",
    "  layers.Dense(7)\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "  optimizer='adam',\n",
    "  loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "  metrics=['accuracy'])\n",
    "\n",
    "EPOCHS = 6\n",
    "history = model.fit(train_batches,\n",
    "                    epochs=EPOCHS,\n",
    "                    validation_data=validation_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(EPOCHS)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import Adam\n",
    "from keras.metrics import categorical_crossentropy\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.applications import imagenet_utils\n",
    "from keras.layers import Dense,GlobalAveragePooling2D\n",
    "from keras.applications import MobileNet\n",
    "from keras.applications.mobilenet import preprocess_input\n",
    "import numpy as np\n",
    "from IPython.display import Image\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mobile = keras.applications.mobilenet.MobileNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Dense, Conv2D, Flatten,Dropout,AveragePooling2D,MaxPooling2D\n",
    "model=MobileNet(include_top=False,input_shape=(224,224, 3))#imports the mobilenet model and discards the last 1000 neuron layer.\n",
    "\n",
    "\n",
    "max_pool3 = MaxPooling2D(pool_size=2)(model.outputs[0])\n",
    "drop = Dropout(0.3)(max_pool3)\n",
    "flat = Flatten()(drop)\n",
    "\n",
    "drop2 = Dropout(0.5)(flat)\n",
    "output = Dense(10, activation='softmax')(drop2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=model.inputs, outputs=output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.layers[:])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# or if we want to set the first 85 layers of the network to be non-trainable\n",
    "for layer in model.layers[:12]:\n",
    "    layer.trainable=True\n",
    "for layer in model.layers[12:87]:\n",
    "    layer.trainable=False\n",
    "for layer in model.layers[87:]:\n",
    "    layer.trainable=True\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "dir = \"dataset\"\n",
    " # dir is your directory path\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type  = os.listdir(dir)\n",
    "\n",
    "for t in type:\n",
    "    dataset_type = os.path.join(dir, t)\n",
    "    classes = os.listdir(dataset_type)\n",
    "    j=0\n",
    "    for c in classes:\n",
    "        c_addr = os.path.join(dataset_type,c)\n",
    "        class_files = os.listdir(c_addr)\n",
    "        for sc in class_files:\n",
    "            image_addr = os.path.join(c_addr,sc)\n",
    "\n",
    "            img = cv2.imread(image_addr)\n",
    "\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ## (2) threshold\n",
    "            th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        ## (3) minAreaRect on the nozeros\n",
    "            pts = cv2.findNonZero(threshed)\n",
    "            ret = cv2.minAreaRect(pts)\n",
    "\n",
    "            (cx,cy), (w,h), ang = ret\n",
    "            if w>h:\n",
    "                w,h = h,w\n",
    "                ang += 0\n",
    "\n",
    "        # (4) Find rotated matrix, do rotation\n",
    "            M = cv2.getRotationMatrix2D((cx,cy), ang, 1.0)\n",
    "            rotated = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "        #img = cv2.warpAffine(threshed, M, (img.shape[1], img.shape[0]))\n",
    "\n",
    "        ## (5) find and draw the upper and lower boundary of each lines\n",
    "            hist = cv2.reduce(rotated,1, cv2.REDUCE_AVG).reshape(-1)\n",
    "\n",
    "            th = 0\n",
    "            H,W = img.shape[:2]\n",
    "            uppers = [y for y in range(H-1) if hist[y]<=th and hist[y+1]>th]\n",
    "            lowers = [y for y in range(H-1) if hist[y]>th and hist[y+1]<=th]\n",
    "\n",
    "            rotated = cv2.cvtColor(rotated, cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "            image_name = [c_addr+\"/image\"+  str(j)+  str(i)+\".jpg\" for i in range(len(uppers))]\n",
    "            j+=1\n",
    "            \n",
    "            \n",
    "            \n",
    "            #print(image_name)\n",
    "                \n",
    "                \n",
    "            print(uppers)\n",
    "            print(lowers)\n",
    "            for i in range(len(uppers)):\n",
    "                \n",
    "                if i==(len(uppers)-1):\n",
    "                    cv2.imwrite(image_name[i], img[uppers[i]:H,0:W])\n",
    "                else:\n",
    "                    cv2.imwrite(image_name[i], img[uppers[i]:lowers[i+1],0:W])\n",
    "\n",
    "                \n",
    "\n",
    "            os.remove(image_addr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type  = os.listdir(dir)\n",
    "\n",
    "for t in type:\n",
    "    dataset_type = os.path.join(dir, t)\n",
    "    classes = os.listdir(dataset_type)\n",
    "    j=0\n",
    "    for c in classes:\n",
    "        c_addr = os.path.join(dataset_type,c)\n",
    "        class_files = os.listdir(c_addr)\n",
    "        for sc in class_files:\n",
    "            image_addr = os.path.join(c_addr,sc)\n",
    "\n",
    "            img = cv2.imread(image_addr)\n",
    "\n",
    "\n",
    "            gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        ## (2) threshold\n",
    "            th, threshed = cv2.threshold(gray, 200, 255, cv2.THRESH_BINARY_INV)\n",
    "            \n",
    "            \n",
    "            hist = cv2.reduce(threshed,0, cv2.REDUCE_AVG).reshape(-1)\n",
    "            \n",
    "            th = 0\n",
    "            H,W = img.shape[:2]\n",
    "            left = [x for x in range(W-1) if hist[x]<=th and hist[x+1]>th]\n",
    "            right = [x for x in range(W-1) if hist[x]>th and hist[x+1]<=th]\n",
    "            \n",
    "            \n",
    "\n",
    "            image_name = [c_addr+\"/image\"+  str(j)+  str(i)+\".jpg\" for i in range(len(left))]\n",
    "            j+=1\n",
    "            \n",
    "            \n",
    "            \n",
    "            print(image_name)\n",
    "                \n",
    "            for i in range(min(len(left),len(right))):\n",
    "                cv2.imwrite(image_name[i],img[0:H,left[i]:right[i]])\n",
    "                \n",
    "                \n",
    "\n",
    "            os.remove(image_addr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a data generator\n",
    "datagen = image_gen_train = ImageDataGenerator(\n",
    "      rescale=1./255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      \n",
    "      fill_mode='nearest')\n",
    "\n",
    "...\n",
    "# load and iterate training dataset\n",
    "train_it = datagen.flow_from_directory('dataset/train/',target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "# load and iterate validation dataset\n",
    "val_it = datagen.flow_from_directory('dataset/Validation/', target_size=(224,224),\n",
    "                                             color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n",
    "# load and iterate test dataset\n",
    "test_it = datagen.flow_from_directory('dataset/test/', target_size=(224,224),\n",
    "                                                 color_mode='rgb',\n",
    "                                                 batch_size=32,\n",
    "                                                 class_mode='categorical',\n",
    "                                                 shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint   \n",
    "\n",
    "# train the model\n",
    "checkpointer = ModelCheckpoint(filepath='dogvgg16.weights.best.hdf5', verbose=1, \n",
    "                               save_best_only=True)\n",
    "model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "# Adam optimizer\n",
    "# loss function will be categorical cross entropy\n",
    "# evaluation metric will be accuracy\n",
    "\n",
    "step_size_train=train_it.n//train_it.batch_size\n",
    "step_size_valid=val_it.n//val_it.batch_size\n",
    "history = model.fit_generator(generator=train_it,\n",
    "                   steps_per_epoch=step_size_train,\n",
    "                    validation_data=val_it,\n",
    "                    validation_steps=step_size_valid,\n",
    "                    callbacks=[checkpointer],\n",
    "                    \n",
    "                   epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(100)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(img_path, show=False):\n",
    "\n",
    "    img = image.load_img(img_path, target_size=(150, 150))\n",
    "    img_tensor = image.img_to_array(img)                    # (height, width, channels)\n",
    "    img_tensor = np.expand_dims(img_tensor, axis=0)         # (1, height, width, channels), add a dimension because the model expects this shape: (batch_size, height, width, channels)\n",
    "    img_tensor /= 255.                                      # imshow expects values in the range [0, 1]\n",
    "\n",
    "    if show:\n",
    "        plt.imshow(img_tensor[0])                           \n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "    return img_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_image = load_image(\"sc3.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(new_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred.argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(output[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras  import applications.ResNet152V2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.applications.resnet_v2.ResNet152V2(include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root] *",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
